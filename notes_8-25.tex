\documentclass{article}

\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage{cmll}
\usepackage{natbib}

\newcommand{\proves}{\vdash}
\newcommand{\provese}{\vdash^\varepsilon}

\newcommand{\consgrade}[1]{\textcolor{blue}{#1}}
\newcommand{\prodgrade}[1]{\textcolor{red}{#1}}
\newcommand{\Ufunc}{\textcolor{red}{\mathcal{U}}}
\newcommand{\U}[2]{\Ufunc\textcolor{black}{(}\consgrade{#1}, \prodgrade{#2}\textcolor{black}{)}}
\newcommand{\Vfunc}{\textcolor{blue}{\mathcal{V}}}
\newcommand{\V}[2]{\Vfunc\textcolor{black}{(}\consgrade{#1}, \prodgrade{#2}\textcolor{black}{)}}

\newcommand{\consring}{\consgrade{\mathcal{R}}}
\newcommand{\prodring}{\prodgrade{\mathcal{P}}}

\newcommand{\bangg}[1]{\mathord{!_{\consgrade{#1}}}}
\newcommand{\queryg}[1]{\mathord{?_{\prodgrade{#1}}}}
\newcommand{\bang}{\bangg{}}
\newcommand{\query}{\queryg{}}

\DeclareMathOperator{\Vector}{Vec}

\title{Notes from August 25, 2017}


\begin{document}

\maketitle

\citet{Hirsch} describe a way of giving semantics to languages with both a consumer effect (or coeffect) and a producer effect.
\citet{Brunel} describe using multiple consumer effects in the form of a graded comonad to do usage analysis.
Finally, \citet{Gaboardi} describe a way of combining a graded comonad and a graded monad in the same language using distributive laws.
However, \citet{Hirsch} describe how distributive laws do not give semantics to some languages with only one consumer effect and one producer effect.
This project attempts to use the technique of \citet{Hirsch} with the graded monads and comonads of \citet{Brunel} and \citet{Gaboardi}.

Importantly, in \citet{Gaboardi}'s work, the producer effects and the consumer effects interact via two functions which describe how both consumer and producer effects change via the distributive law.
At first glance, it is less clear that they interact in a similar way in \citet{Hirsch}'s work, where the effects are described as interacting via \emph{timing}: either the producer effect is resolved first, or the consumer effect is.
However, if we use an example of classical linear logic, we get the type system in Figure~\ref{fig:gradedcll}, which has a \citet{Gaboardi}-style interaction.

The grading is done via two rings, $\langle \consring, \consgrade{+}, \consgrade{\cdot}, \consgrade{0}, \consgrade{1} \rangle$ which describe the consumer effects (and the grading on the comonad) and $\langle \prodring, \prodgrade{+}, \prodgrade{\cdot}, \prodgrade{0}, \prodgrade{1} \rangle$ which describes the producer effects (and the grading on the monad).
There are two functions $\Ufunc :\consring \times \prodring \to \prodring$ and $\Vfunc : \consring \times \prodring \to \consring$.
These lift naturally to vectors.
(Note the use of colors to clarify types: all consumer effects/coeffect grades will be written in \consgrade{blue}, while all producer effects/effect grades will be written in \prodgrade{red}.)

\begin{figure}[h]
  \centering
$$\setlength\arraycolsep{20pt}
\renewcommand{\arraystretch}{3}
\begin{array}{cc}
  \multicolumn{2}{c}{\infer{ }{\tau \vdash \tau}}\\
  \infer{\Gamma, \varphi, \psi \proves \Delta}{\Gamma, \varphi \otimes \psi \proves \Delta} & \infer{\Gamma \proves \varphi, \Delta\\\Gamma' \proves \psi, \Delta}{\Gamma, \Gamma' \proves \varphi \otimes \psi, \Delta, \Delta'}\\
  \infer{\Gamma, \varphi \proves \Delta\\ \Gamma', \psi \proves \Delta'}{\Gamma, \Gamma', \varphi \parr \psi \proves \Delta, \Delta'} & \infer{\Gamma \proves \varphi, \psi, \Delta}{\Gamma \proves \varphi \parr \psi, \Delta}\\
  \infer{\Gamma, \varphi \proves \Delta}{\Gamma, \bangg{1}\varphi \proves \Delta} & \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{r' \cdot \vec{r}} \proves \bangg{r'}\varphi, \queryg{\U{r'}{\vec{e}}}\Delta}\\
  \infer{\Gamma, \bangg{r}\varphi, \bangg{s}\varphi \proves \Delta}{\Gamma \bangg{r + s}\varphi \proves \Delta} & \infer{\Gamma \proves \Delta}{\Gamma, \bangg{0}\varphi \proves \Delta}\\
  \infer{\Gamma \proves \varphi, \Delta}{\Gamma \proves \queryg{1}\varphi, \Delta} & \infer{\bangg{\vec{r}}\Gamma, \varphi \proves \queryg{\vec{e}}\Delta}{\bangg{\V{\vec{r}}{e}}\Gamma, \queryg{e}\varphi \proves \queryg{\vec{e}\cdot e}\Delta}\\
  \infer{\Gamma \proves \queryg{e}\varphi, \queryg{e'}\varphi, \Delta}{\Gamma \proves \queryg{e + e'}\varphi, \Delta} & \infer{\Gamma \proves \Delta}{\Gamma \proves \queryg{0}\varphi, \Delta}
\end{array}$$

\caption{Graded Classical Linear Logic}
\label{fig:gradedcll}
\end{figure}

The functions $\Ufunc$ and $\Vfunc$ must satisfy certain laws for cut elimination to hold.
We look at the cut elimination steps and the equations these force on $\Ufunc$ and $\Vfunc$ now.


\section{Cutting Left Promotion}
\paragraph{With Left Contraction} Consider the case where we cut a left promotion with a left contraction:
$$\infer{
  \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r} \cdot (s_1 + s_2)}\Gamma \proves \bangg{s_1 + s_2}\varphi, \queryg{\U{s_1 + s_2}{\vec{e}}}\Delta}\\
  \infer{\Gamma', \bangg{s_1} \varphi, \bangg{s_2} \varphi \proves \Delta'}{\Gamma', \bangg{s_1 + s_2} \varphi \proves \Delta}}
{\bangg{\vec{r} \cdot (s_1 + s_2)}\Gamma, \Gamma' \proves \queryg{\U{s_1 + s_2}{\vec{e}}}\Delta, \Delta'}$$
One application of cut-elimination gives:
$$\infer {
  \infer{
    \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r} \cdot s_2}\Gamma \proves \bangg{s_2}\varphi, \queryg{\U{s_2}{e}}\Delta}\\
    \infer{
      \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r} \cdot s_1}\Gamma \proves \bangg{s_1}\varphi, \queryg{\U{s_1}{e}}\Delta}\\
      \infer{}{\Gamma', \bangg{s_1}\varphi, \bangg{s_2}\varphi \proves \Delta'}}
    {\bangg{\vec{r} \cdot s_1}\Gamma, \Gamma', \bangg{s_2}\varphi \proves \queryg{\U{s_1}{e}}\Delta, \Delta'}}
  {\bangg{\vec{r} \cdot s_1}\Gamma, \bangg{\vec{r} \cdot s_1}\Gamma, \Gamma' \proves \queryg{\U{s_1}{e}}\Delta, \queryg{\U{s_2}{e}}\Delta, \Delta'}}
{\bangg{\vec{r} \cdot s_1 + \vec{r} \cdot s_1}\Gamma, \Gamma' \proves\queryg{\U{s_1}{e} + \U{s_2}{e}}\Delta, \Delta'}$$
This gives rise to the following function equation:
$$\U{r_1 + r_2}{\vec{e}} = \U{r_1}{\vec{e}} + \U{r_2}{\vec{e}}$$
It also gives evidence that we need the following ring axiom:
$$\color{blue} r \cdot  (s_1 + s_2) = (r \cdot s_1) + (r \cdot s_2)$$
\paragraph{With Left Weakening} Cutting left promotion with left weakening gives:
$$\infer{
  \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r} \cdot 0}\Gamma \proves \bangg{0}\varphi, \queryg{\U{0}{\vec{e}}}\Delta}\\
  \infer{\Gamma' \proves \Delta'}{\Gamma', \bangg{0}\varphi \proves \Delta'}}
{\bangg{\vec{r} \cdot 0}\Gamma, \Gamma' \proves \queryg{\U{0}{\vec{e}}}\Delta}$$
After one application of cut elimination, we get:
$$\infer{\Gamma' \proves \Delta'}{\bangg{0}\Gamma, \Gamma' \proves \queryg{0}\Delta, \Delta'}$$
This gives rise to the equation
$$\U{0}{\vec{e}} = \prodgrade{0}$$
and also gives evidence that we need the ring identity
$$\color{blue}r \cdot 0 = 0$$
\paragraph{With Left Dereliction}Consider cutting a left promotion with dereliction:
$$\infer{
  \infer{\bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r}\cdot 1} \proves \bangg{1}\varphi, \queryg{\U{1}{\vec{e}}}\Delta}\\
  \infer{\Gamma', \varphi \proves \Delta'}{\Gamma', \bangg{1}\varphi \proves \Delta'}}
{\bangg{\vec{r} \cdot 1}\Gamma, \Gamma' \proves \queryg{\U{1}{\vec{e}}}\Delta, \Delta'}$$
One application of the cut-elimination procedure gives:
$$\infer{
  \bangg{\vec{r}}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta\\
  \Gamma', \varphi \proves \Delta}
{\bangg{\vec{r}}\Gamma, \Gamma' \proves \queryg{\vec{e}}\Delta, \Delta'}$$

This shows that we need the equation
$$\U{1}{\vec{e}} = \prodgrade{\vec{e}}$$
and that we need the ring identity
$$\color{blue} r \cdot 1 = 1$$

\paragraph{With Left Promotion}Consider the case where we cut a left promotion with a left promotion:
$$\infer{
  \infer{\bangg{\vec{r}_1}\Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r}_1 \cdot s_1 \cdot s_2} \Gamma \proves \bangg{s_1 \cdot s_2} \varphi, \queryg{\U{s_1 \cdot s_2}{\vec{e}}} \Delta}\\
  \infer{\bangg{\vec{r}_2}\Gamma', \bangg{s_1}\varphi \proves \psi, \query{\vec{e}'}\Delta'}{\bangg{\vec{r}_2 \cdot s_2}\Gamma', \bangg{s_1 \cdot s_2}\varphi \proves \bangg{s_2}\psi, \queryg{\U{s_2}{\vec{e}'}}\Delta'}}
{\bangg{\vec{r}_1}\Gamma, \bangg{\vec{r}_2}\Gamma' \proves \bangg{s_2}\psi, \queryg{\U{s_1 \cdot s_2}{\vec{e}}} \Delta, \queryg{\U{s_2}{\vec{e}'}}\Delta'}$$
One application of the cut-elimination procedure gives:
$$
\infer{ 
  \infer{
    \infer{\bangg{\vec{r}_1} \Gamma \proves \varphi, \queryg{\vec{e}}\Delta}{\bangg{\vec{r}_1 \cdot s_1}\Gamma \proves \bangg{s_1}\varphi, \queryg{\U{s_1}{\vec{e}}}\Delta}\\
    \infer{}{\bangg{\vec{r}_2} \Gamma', \bangg{s_1}\varphi \proves \psi, \queryg{\vec{e}'}\Delta'}}
  {\bangg{\vec{r}_1 \cdot s_1}\Gamma, \bangg{\vec{r}_2} \Gamma' \proves \psi, \queryg{\U{s_1}{\vec{e}}}\Delta, \queryg{\vec{e}'}\Delta'}}
{\bangg{\vec{r}_1 \cdot s_1 \cdot s_2}\Gamma, \bangg{\vec{r}_2 \cdot s_2} \Gamma' \proves \bangg{s_2} \psi, \queryg{\U{s_2}{\U{s_1}{\vec{e}}}}\Delta, \queryg{\U{s_2}{\vec{e}'}}\Delta'}
$$
This gives rise to the following equation:
$$\U{r_1 \cdot r_2}{\vec{e}} = \U{r_2}{\U{r_1}{\vec{e}}}$$

\paragraph{With Right Promotion} Consider the case where we cut a left promotion with a right promotion:
$$\infer{
  \infer{\bangg{r}\Gamma \proves \varphi, \queryg{e}\psi, \queryg{\vec{e}} \Delta}{\bangg{r \cdot r'}\Gamma \proves \bangg{r'}\varphi, \queryg{\U{r'}{e}}\psi, \queryg{\U{r'}{\vec{e}}}\Delta}\\
  \infer{\bangg{s}\Gamma', \psi \proves
    \queryg{\vec{e}'}\Delta'}{\bangg{\V{s}{\U{r'}{e}}}\Gamma',
    \queryg{\U{r'}{e}}\psi \proves \queryg{\U{r'}{e} \cdot
      \vec{e}'}\Delta'}} {\bangg{r \cdot r'}\Gamma,
  \bangg{\V{s}{\U{r'}{e}}}\Gamma' \vdash \bangg{r'}\varphi,
  \queryg{\U{r'}{\vec{e}}}\Delta, \queryg{\U{r'}{e} \cdot
    \vec{e}'}\Delta'}$$
One application of the cut-elimination procedure gives:
$$\infer{ \infer{
    \infer{}{\bangg{r}\Gamma \proves \varphi, \queryg{e}\psi, \queryg{\vec{e}} \Delta}\\
    \infer{\bangg{s}\Gamma', \psi \proves \queryg{\vec{e}'}
      \Delta'}{\bangg{\V{s}{e}} \Gamma', \queryg{e}{\psi} \proves
      \queryg{e \cdot \vec{e}'} \Delta}} {\bangg{r}\Gamma,
    \bangg{\V{s}{e}} \Gamma' \proves \varphi, \queryg{\vec{e}}
    \Delta, \queryg{e \cdot \vec{e}'} \Delta}} {\bangg{r \cdot
    r'}\Gamma, \bangg{\V{s}{e} \cdot r'} \Gamma' \proves
  \bangg{r'}\varphi, \queryg{\U{r'}{\vec{e}}} \Delta,
  \queryg{\U{r'}{e \cdot \vec{e}'}} \Delta}$$
This gives rise to two equations:
$$\V{r}{\U{r'}{e}} = \V{r}{e} \cdot \consgrade{r'}$$
$$\U{r}{\vec{e}} \cdot \prodgrade{e} = \U{r}{e \cdot \vec{e}}$$

\paragraph{Summary} To sum up, after the following reasoning (and dualizing by cutting with right promotion) we need the following:\\
\begin{minipage}{0.5\linewidth}
  \begin{itemize}
  \item $\U{0}{e} = \prodgrade{0}$
  \item $\U{1}{e} = \prodgrade{e}$ 
  \item $\U{r_1 + r_2}{e} = \U{r_1}{e} \prodgrade{+} \U{r_2}{e}$
  \item $\U{r_1 \cdot r_2}{e} = \U{r_2}{\U{r_1}{e}}$
  \item $\U{r}{e} \prodgrade{\cdot} \prodgrade{e'} = \U{r}{e \cdot e'}$
  \item $\U{\V{r}{e'}}{e} = e' \cdot \U{r}{e}$
  \end{itemize}
\end{minipage}
\begin{minipage}{0.5\linewidth}
  \begin{itemize}
  \item $\V{r}{0} = \consgrade{0}$
  \item $\V{r}{1} = \consgrade{r}$ 
  \item $\V{r}{e_1 + e_2} = \V{r}{e_1} \consgrade{+} \V{r}{e_2}$
  \item $\V{r}{e_1 \cdot e_2} = \V{\U{r}{e_1}}{e_2}$
  \item $\V{r}{e} \consgrade{\cdot} \consgrade{r'} = \U{r \cdot r'}{e}$
  \item $\V{r}{\U{r'}{e}} = \V{r}{e} \cdot \consgrade{r'}$
  \end{itemize}
\end{minipage}

\section{Motivating Language Example}

We want to think about a parallel language which uses network bandwidth both down and up.
We use bandwidth down when we use an input, since we need to download the inputs from the network.
We use bandwidth up when we produce and output, since we need to upload the outputs to the network.

In this case, we can use the linear logic type system described above (perhaps with extensions).
Then, both $\consring$ and $\prodring$ are the natural numbers with the standard interpretation of the natural numbers as a ring.
Moreover $\U{r}{e} = r \cdot e$ and $\V{r}{e} = r \cdot e$.
With this interpretation, the above equations are satisfied.

\paragraph{Note 9-7-2017}
I wrote down something Marco mentioned earlier: that he has two types of cost-counting analyses.
One uses a traditional Kleisli-style arrow $$A \to M_c B$$ which calculates cost correctly in a call-by-value language. 
The other uses arrows of the form $$M_{c_1} A \to M_{c_2} B,$$ which calculates cost in a call-by-name language.

It occurs to me that, since his call-by-name language almost certainly allows arbitrary weakening and contraction, that it exists in the coKleisli category for a $\bang$ operator.
That is, the call-by-name arrows are actually of the form $$\bang M_{c_1} A \to M_{c_2} B,$$ which is predicted by \citet{Hirsch}.
Since there does not seem to be a distributive law between $\bang$ and $\queryg{n}$, it is likely that the strict case acts over the functor category for $\bang$, so that the call-by-value arrows are actually of the form $\bang A \to M_{c}\bang B$, as predicted by \citet{Hirsch}.
However, this seems to indicate that the strict and lazy notions from \citet{Hirsch} should generalize in this work.

\section{Motivating Reasoning Example}

Imagine an analysis where terms may be either terminating or possibly-non-terminating (as producer effects) and may be used any natural number of times (as consumer effects).
Then, we would like to show that the term $3$ terminates in a lazy context.
In \citet{Hirsch}, we can prove this as a metatheorem.
However, we would like to be able to read this off the type of a thunked program (in \citet{Hirsch}'s parlance).
This would be a proof of the typing judgment $x : \bangg{0}\queryg{\mathrm{pnt}} \proves 3 : \queryg{\mathrm{t}} \mathbb{N}$ where pnt stands for ``possibly non-terminating'' and ``t'' stands for ``terminating.''

Because $\queryg{\mathrm{t}}$ is the identity functor, this is the same as a judgment of the form $x : \bangg{0}\queryg{\mathrm{pnt}} \proves 3 : \mathbb{N}$.
This is provable in \citet{Hirsch}'s type system, by applying weakening.
However, the ``analyzed'' (thunked) programs do not reveal this, since every function is listed as possibly not terminating.

\section {Roadmap}

\begin{enumerate}
\item Work out the full example of graded classical linear logic, with a term calculus
\item Work out a more-general example where we do not assume a quantitative nature
\item Describe more examples where the sort of reasoning given above can make analyses more precise
\item What semantic properties of (graded) monads/producers and (graded) comonads/consumptors are we assuming to get the bind/promotion rules above?
\end{enumerate}

\bibliographystyle{plainnat}
\bibliography{graded-pc,effects}

\end{document}